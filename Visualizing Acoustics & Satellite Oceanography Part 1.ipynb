{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Open Source Acoustic Metrics and Their Relationship to Satellite Oceanography: Part 1 (Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emily Speciale, Charles Anderson, Veronica Martinez, Carrie Wall Bell, & Adrienne Copeland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script outlines how to extract backscatter data from a cruise, mask the data for seafloor and surface noise, and collect the cruise's echometric data into a csv file. We recommend using PyCharm for this procedure. \n",
    "\n",
    "Upon downloading and opening PyCharm, click \"Get from VCS\". Paste the URL for pyEchoLab (https://github.com/CI-CMG/pyEcholab), then press \"Clone\". Repeat this for Echometrics (https://github.com/ElOceanografo/EchoMetrics). Then, open up your pyEchoLab workspace, click File > Open, and choose your Echometrics folder. When the pop-up appears, click \"Attach\" to install Echometrics into your pyEchoLab library. \n",
    "\n",
    "If using Jupyter Notebook, you can use terminal to download both pyEchoLab and Echometrics. Use the commands:\n",
    "pip install git+https://github.com/CI-CMG/pyEcholab.git\n",
    "pip install git+https://github.com/ElOceanografo/EchoMetrics\n",
    "\n",
    "The other step we must take before beginning is downloading our cruise data. We recommend storing this data on a hard drive, as cruise data can contain up to hundreds of gigabytes of data. For this notebook, we are working with the Okeanos Explorer EX1903L1 and EX1903L2 raw data, which can be seen here: https://noaa-wcsd-pds.s3.amazonaws.com/index.html#data/raw/Okeanos_Explorer/EX1903L1/EK60/. \n",
    "\n",
    "In order to download the data onto your computer, make sure set up an AWS account and download AWS CLI, and use your terminal for the download. We created folders specifically for EX1903L1 and EX1903L2 data in our hard drive. For instance, in order to download EX1903L1, we entered into our terminal: \n",
    "aws s3 sync s3://noaa-wcsd-pds/data/raw/Okeanos_Explorer/EX1903L1/EK60/  /Volumes/Emily_Passport/EX1903L1/ --no-sign-request\n",
    "\n",
    "We then did the same for the EX1903L2. Both .raw and .idx files will download into our folders. In order to make processing the data easier, we created an EX1903_raw folder, and moved only the raw files from EX1903L1 and EX1903L2 into that folder. *Warning, depending on your computer's strength, downloading this data may take a few days, with the download occasionally stopping. Just repeatedly enter the terminal line above and the data will continue to sync and download.*\n",
    "\n",
    "Now that we have everything downloaded we can started coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from echolab2.instruments import EK80\n",
    "from echolab2.processing.batch_utils import FileAggregator as fa\n",
    "from echometrics import echometrics as ec\n",
    "import numpy as np\n",
    "from echolab2.plotting.matplotlib import echogram\n",
    "from matplotlib.pyplot import figure, show, subplots_adjust\n",
    "from echolab2.processing import afsc_bot_detector\n",
    "from echolab2.processing.mask import mask\n",
    "from echolab2.processing.line import line\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    plt = None\n",
    "    print(\"Warning: could not import from matplotlib. Echogram.show() will not work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up New CSV File and Cruise Data\n",
    "\n",
    "First we create a blank .csv file and write in our headings for our columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open('cruise_data.csv', 'w')\n",
    "output_file.write(\"Latitude,Longitude,Range,Time,Sv_Avg,Center_of_Mass,Inertia,\"\n",
    "                  \"Proportion_Occupied,Aggregation_Index,Equivalent_Area\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this cruise, we only want to examine data from the 18 kHz channel. After setting our freq to 18000, we use the file aggregator to bin the files into thirty minute time intervals. Thus, we will be collecting the average latitude, longitude, range, echometric value, etc. for each thirty minutes. We will be calling each time interval an index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 18000\n",
    "raw_files = fa('/Volumes/Emily_Passport/EX1903_raw', interval=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data, Masking Seafloor, and Collecting Echometric Data for each Index\n",
    "\n",
    "We will be using a for loop to run through each index to extract the Sv data, apply masks, and collect that index's average lat/lon, range, and echometrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file_list in enumerate(raw_files.file_bins):\n",
    "    \n",
    "    # Print the index number and the files within the index.\n",
    "    file_list = file_list\n",
    "    print(index, file_list)\n",
    "    \n",
    "    # Use the EK80 class to read the raw files within our index and collect data from all \n",
    "    # its channels. *Although EX1903 used an EK60, its EK60 had parts of an EK80, thus its\n",
    "    # file format was produced in EK80 format. If using EK60 data, simply change the ek80s \n",
    "    # to ek60s. \n",
    "    ek80 = EK80.EK80()\n",
    "    try:\n",
    "        ek80.read_raw(file_list)\n",
    "        \n",
    "        # Get channel data only from our frequency of interest (18 kHz).\n",
    "        raw_data = ek80.get_channel_data(frequencies=freq)\n",
    "        \n",
    "        # Get our mean volume-backscattering strength data, or Sv (backscatter) data, from our 18 kHz channel.\n",
    "        Sv = raw_data[freq][0].get_Sv(heave_correct=True)\n",
    "        \n",
    "        # Optional: to check data, plot an echogram of the raw Sv data.\n",
    "        fig = figure()\n",
    "        ax1 = fig.add_subplot(2, 1, 1)\n",
    "        eg = echogram.Echogram(ax1, Sv, threshold=[-145, 10])\n",
    "        ax1.set_title('Original 18 kHz Sv Data')\n",
    "        \n",
    "        # There will be noise within the first 6 meters of data from the transducer. The seafloor/bottom \n",
    "        # also produces a lot of noise that we want to remove from our data. Create a mask to hold \n",
    "        # bottom and surface exclusion.\n",
    "        bot_surf_mask = mask(like=Sv)\n",
    "        \n",
    "        # Create a surface exclusion line at data=Xm RANGE.\n",
    "        surf_line = line(ping_time=Sv.ping_time, data=6)\n",
    "        \n",
    "        # Now apply our surface line to this same mask.\n",
    "        bot_surf_mask.apply_line(surf_line, apply_above=True)\n",
    "        \n",
    "        # Since we'll be passing our bottom detector data on a depth grid, set this to the minimum \n",
    "        # DEPTH in meters to search for the bottom\n",
    "        search_min = 15\n",
    "        \n",
    "        # Since we'll be passing Sv data to the bottom detector, set the backstepin Sv(dB). \n",
    "        back_step = 30\n",
    "        bot_detector = afsc_bot_detector.afsc_bot_detector(search_min=search_min, backstep=back_step)\n",
    "        \n",
    "        # Now use our simple bottom detector to pick a bottom line for the data.The bottom detector \n",
    "        # class returns a pyEcholab2 line object representing the bottom.\n",
    "        bottom_detected = bot_detector.detect(Sv)\n",
    "        \n",
    "        # Next create a new line that is 3 m shallower(in place operators will change the existing line).\n",
    "        bottom_line = bottom_detected - 3.0\n",
    "        \n",
    "        # Now apply our bottom line to the mask.\n",
    "        bot_surf_mask.apply_line(bottom_line, apply_above=False)\n",
    "        \n",
    "        # Now use this mask to set sample data from 0.5m above the bottom downward to NaN.\n",
    "        Sv[bot_surf_mask] = np.NaN\n",
    "        \n",
    "        # Optional: to check data, plot an echogram of the Sv data now with a masked surface and bottom.\n",
    "        ax_3 = fig.add_subplot(3, 1, 3)\n",
    "        echogram_3 = echogram.Echogram(ax_3, Sv, 'data', threshold=[-145, 10])\n",
    "        ax_3.set_title(\"Sv after bottom and surface removal\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    # Now that we have our clean data, we want to find the latitude and longitude positions\n",
    "    # of our indexes. We use the first latitude and longitude value of each index. \n",
    "    try:\n",
    "        positions = ek80.nmea_data.interpolate(Sv, 'position')\n",
    "        latitude = positions[1]['latitude']\n",
    "        latitude = latitude[1]\n",
    "        longitude = positions[1]['longitude']\n",
    "        longitude = longitude[1]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    # We will now use the class echogram from Echometrics to begin our calculations. The echogram\n",
    "    # class requires these parameters: (data, depth, index, scale=decibel, threshold=[-80, 0], bad_data=None). \n",
    "    try:\n",
    "        data = ec.Echogram(np.transpose(Sv.data), Sv.range, Sv.ping_time, scale=\"linear\", \n",
    "                           threshold=[-80, -34], bad_data=None)\n",
    "        \n",
    "        # Get the average range and the first ping time for each index.\n",
    "        Sv.range = np.average(Sv.range)\n",
    "        Sv.ping_time = Sv.ping_time[0]\n",
    "        \n",
    "        # We can begin calculating the echometrics (more specifically, their averages for our indexes). \n",
    "        # Our first echometric is Sv, which is a proxy for density and has a unit of dB re 1 m^-1. \n",
    "        sv_avg = ec.sv_avg(data)\n",
    "        sv_avg = np.average(sv_avg)\n",
    "        \n",
    "        # Our second echometric is center of mass, which describes the average location of noise in\n",
    "        # ping, in units of meters (m).\n",
    "        com = ec.center_of_mass(data)\n",
    "        com = np.average(com)\n",
    "        \n",
    "        # Our third echometric is inertia, which measures the dispersion or spread of backscatter\n",
    "        # in the ping in units of m^-2. \n",
    "        inertia = ec.inertia(data)\n",
    "        inertia = np.average(inertia)\n",
    "       \n",
    "        # Our fourth echometric is proportion occupied, which calculates the proportion of the ping\n",
    "        # with an Sv above -90 dB. \n",
    "        po = ec.proportion_occupied(data)\n",
    "        po = np.average(po)\n",
    "        \n",
    "        # Our fifth echometric is equivalent area, which measures the evenness of the ping's backscatter.\n",
    "        # It has units of meters (m).\n",
    "        ai = ec.aggregation_index(data)\n",
    "        ai = np.average(ai)\n",
    "    \n",
    "        # Our sixth echometric is the aggregation index, which is the opposite of equivalent area; when small\n",
    "        # areas are denser than the rest of the distribution, AI is high. Its units are m^-1.\n",
    "        ea = ec.equivalent_area(data)\n",
    "        ea = np.average(ea)\n",
    "        \n",
    "        # Finally, we add all of our calculations of lat/lon, range, ping time, and our echometrics to our\n",
    "        # .csv file. \n",
    "        data_list = f\"{latitude},{longitude},{Sv.range},{Sv.ping_time},{sv_avg},{com},{inertia},{po},{ai},{ea}\\n\"\n",
    "        output_file.write(data_list)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "# Upon collecting data for all the indexes, we close the .csv file.\n",
    "output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
